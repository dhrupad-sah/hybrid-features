{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prasad\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\Prasad\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import ResNetForImageClassification\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from torch.nn import Sequential as SequentialTorch, Flatten as FlattenTorch\n",
    "from sklearn.svm import NuSVC, SVC\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import ast\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'microsoft/resnet-50'\n",
    "model = ResNetForImageClassification.from_pretrained(model_checkpoint)\n",
    "\n",
    "model.classifier = SequentialTorch(\n",
    "    FlattenTorch(start_dim=1, end_dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv.ORB_create(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./test_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "handcrafted_features = []\n",
    "deep_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_from_image_name(image_name):\n",
    "    # Assuming the label is encoded in the last 9 characters\n",
    "    label = image_name[-14:-5]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(folder_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in os.listdir(folder_path):\n",
    "    # Assuming image names have a code that corresponds to the label\n",
    "    label = extract_label_from_image_name(image_name)\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image_path = os.path.join(folder_path, image_name)\n",
    "    img = cv.imread(image_path)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # ORB feature extraction\n",
    "    kp = orb.detect(img, None)\n",
    "    if kp:\n",
    "        kp, des = orb.compute(img, kp)\n",
    "        handcrafted_features.append(des.flatten())\n",
    "\n",
    "        # Check if descriptors are not None and not empty\n",
    "        if des is not None and des.size > 0:\n",
    "            # ResNet-50 feature extraction\n",
    "            image = Image.open(image_path).resize((224, 224))\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "            image = transform(image)\n",
    "            inputs = image.unsqueeze(0)\n",
    "            outputs = model(inputs)\n",
    "            logits = outputs.logits\n",
    "            resnet_features = logits.detach().numpy().flatten()\n",
    "            deep_features.append(resnet_features)\n",
    "\n",
    "            # Check if resnet_features is not empty\n",
    "            if resnet_features.size > 0:\n",
    "                # Combine features\n",
    "                # combined_features = np.stack((resnet_features, des.flatten()), axis=1)\n",
    "\n",
    "                # Append to lists\n",
    "                # features.append(combined_features)\n",
    "                labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248\n",
      "352\n",
      "512\n",
      "loop done\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(handcrafted_features)):\n",
    "    if type(handcrafted_features[i]) != list:\n",
    "        handcrafted_features[i] = handcrafted_features[i].tolist()\n",
    "    if len(handcrafted_features[i]) != 2048:\n",
    "        print(len(handcrafted_features[i]))\n",
    "        handcrafted_features[i] = handcrafted_features[i] + [0]*(2048 - len(handcrafted_features[i]))\n",
    "        \n",
    "print('loop done')\n",
    "        \n",
    "for i in range(len(handcrafted_features)):\n",
    "    if len(handcrafted_features[i]) != 2048:\n",
    "        print(len(handcrafted_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "handcrafted_features = np.array(handcrafted_features)\n",
    "deep_features = np.array(deep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = np.stack((deep_features, handcrafted_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './LOC_synset_mapping.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    class_to_name_dict = {}\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            parts = line.split(' ', 1)\n",
    "            class_label = parts[0]\n",
    "            class_name = parts[1]\n",
    "            \n",
    "            class_to_name_dict[class_label] = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './imagenet1000_clsidx_to_labels.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "    extracted_dict = ast.literal_eval(content)\n",
    "\n",
    "class_name_to_numeric_class_dict = {value: key for key, value in extracted_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65, 970, 230, 809, 516, 57, 334, 415, 674, 332, 109, 286, 370, 757, 595, 147, 108, 23, 478, 517, 334, 173, 948, 727, 23, 846, 270, 167, 55, 858, 324, 573, 150, 981, 586, 887, 32, 398, 777, 74, 516, 756, 129, 198, 256, 725, 565, 167, 717, 394, 92, 29, 844, 591, 358, 468, 259, 994, 872, 588, 474, 183, 107, 46, 842, 390, 101, 887, 870, 841, 467, 149, 21, 476, 80, 424, 159, 275, 175, 461, 970, 160, 788, 58, 479, 498, 369, 28, 487, 50, 270, 383, 366, 780, 373, 705, 330, 142, 949, 349, 473, 159, 872, 878, 201]\n"
     ]
    }
   ],
   "source": [
    "mapped_labels = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    class_name_for_label = class_to_name_dict[labels[i]]\n",
    "    numeric_label = class_name_to_numeric_class_dict[class_name_for_label]\n",
    "    mapped_labels.append(numeric_label)\n",
    "    \n",
    "print(mapped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 2048) (94,) (11, 2048) (11,)\n"
     ]
    }
   ],
   "source": [
    "mapped_labels = np.array(mapped_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(handcrafted_features, mapped_labels, test_size=0.1, random_state=100)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = lda.transform(X_train)\n",
    "svc = SVC()\n",
    "svc.fit(transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.0\n"
     ]
    }
   ],
   "source": [
    "transformed_test = lda.transform(X_test)\n",
    "preds = svc.predict(transformed_test)\n",
    "print(f'Accuracy is : {accuracy_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
